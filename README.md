# ImageCaptionGenerator-700747726
## Abstract

Globally there are 2.2 billion people who are visually
impaired. They need assistance for reading or checking the information.With the help of deep learning we extract the information
from images and process and read it out to the people.Deep
learning is a technique which processes the information in the
images and translates it into useful information.Deep learning is a
subset of machine learning and the models contain three or more
layers which extract the information.Image captioning projects
deal with understanding the information in the images like
humans do, producing the text describing what is happening in
the image.In this project we propose a neural network approach
LSTM for text classification to generate the meaningful captions
and VGG16 transfer learning model to process the images and
extract features. In the end the performance of the test dataset is
evaluated using accuracy and BLEU score to check the accuracy
of the predictions. The experimental analysis is conducted on
publicly available Flickr8k image dataset.
